---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.14.5
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```{python}
# %cd '/Users/jialongwang/Documents/University of Waterloo Course/STAT441 - Classificaiton/Final Project'   
```

### One-Hot-Encoding the Classes Variate for NN

```{python}
import pandas as pd
```

```{python}
train=pd.read_csv("datasets/imputed_training_data.csv")
# use the following
# train=pd.read_csv("datasets/imputed_training_data.csv")

test=pd.read_csv('datasets/imputed_test_data.csv')
```

```{python}
test.head()
```

```{python}
xTrain=train.drop(['STAT_CAUSE_DESCR'], axis=1).values 
yTrain=train['STAT_CAUSE_DESCR'].values 
xTest=test.drop(['STAT_CAUSE_DESCR'],axis=1).values
yTest=test['STAT_CAUSE_DESCR'].values
```

```{python}
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
```

```{python}
encoder=LabelEncoder()
encoder.fit(yTrain)
yTrain_1col = encoder.transform(yTrain)
yTest_1col = encoder.transform(yTest)
```

```{python}
encoder.classes_
```

```{python}
yTrain=yTrain_1col.reshape(-1,1)
yTest=yTest_1col.reshape(-1,1)
```

```{python}
encoder=OneHotEncoder()
encoder.fit(yTrain)
yTrain=encoder.transform(yTrain)
yTest=encoder.transform(yTest)
```

```{python}
encoder.get_feature_names_out(["CAUSE"])
```

```{python}
yTrain=yTrain.toarray()
yTest=yTest.toarray()
```

```{python}
from sklearn.model_selection import train_test_split
xTrain,xVal,yTrain,yVal=train_test_split(xTrain,yTrain,\
                           test_size=0.1,random_state =441)

```

```{python}
# from tensorflow import keras
# num_classes = 11
# yTrain = keras.utils.to_categorical(yTrain, num_classes)
# #yVal = keras.utils.to_categorical(yVal, num_classes)
# yTest = keras.utils.to_categorical(yTest, num_classes)
```

### Building a NN Model

```{python}
from tensorflow import keras
from tensorflow.keras import layers
```

```{python}
# Build a model 
def build_model():
    model = keras.Sequential()
    
    #input layer
    model.add(layers.Dense(units=128, activation='relu', input_shape = (xTrain.shape[1],))) 
    
    #hidden layer(s)
    model.add(layers.Dense(units=128, activation="relu"))
    
    model.add(layers.Dense(units=128, activation="relu"))
    
    model.add(layers.Dense(units=128, activation="relu"))
    
    #model.add(layers.Dense(units=256, activation="relu"))
    
    #model.add(layers.Dense(units=256, activation="relu"))
    
    #model.add(layers.Dense(units=256, activation="relu"))
   
    #Output Layer
    model.add(layers.Dense(11,activation='softmax'))
    
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.001),
        loss="categorical_crossentropy",
        metrics=["accuracy"],
    )
    return model
```

```{python}
model2=build_model()
model2.summary()
```

```{python}
model3=build_model()
model3.summary()
```

```{python}
# %%time
EPOCHS = 60

history = model3.fit(
        xTrain, 
        yTrain,
        epochs=EPOCHS, 
        verbose=1,
        shuffle=True,
        validation_data = (xVal, yVal),
    )
```

```{python}
from sklearn.metrics import classification_report

predict_results = model3.predict(xTest)
predict_results= predict_results.argmax(axis = 1)
target_names = ['Arson', 'Campfire', 'Children','Debris Burning','Equipment Use',
               'Fireworks','Lighting','Powerline','Railroad','Smoking','Structure']

report_SMOTE=classification_report(yTest_1col, predict_results, target_names=target_names)
print(report_SMOTE)
```

```{python}
predict_results = model3.predict(xTest)
predict_results= predict_results.argmax(axis = 1)
report_Non_SMOTE=classification_report(yTest_1col, predict_results,
                                       target_names=target_names)
print(report_Non_SMOTE)
```

```{python}
model2.evaluate(xTest,yTest)
```

```{python}
from matplotlib import pyplot as plt
plt.rcParams["figure.figsize"] = (5,3)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy-3*128 SMOTE')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()
```

```{python}
import seaborn as sns
import matplotlib.pyplot as plt     
from sklearn.metrics import confusion_matrix

plt.rcParams["figure.figsize"] = (12,12)
ax= plt.subplot()
predict_results = model2.predict(xTest)

# predict_results = (predict_results.argmax())
predict_results= predict_results.argmax(axis = 1)

cm = confusion_matrix(yTest_1col, predict_results)

sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells

# labels, title and ticks
ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); 
ax.set_title('Confusion Matrix'); 
# ax.xaxis.set_ticklabels(['Positive', 'Negative']); ax.yaxis.set_ticklabels(['Positive', 'Negative']);
```

```{python active="", eval=FALSE}
Because of limitation of the computational power, doing hyperparameter tuning mannually by Trail and Error. Which is the same ideas as keras.tunner. Since what keras.tunner do is that it would try different combination of number of layers and number of nodes in each layer for us. And we can do exactly that by ourself.
```

```{python active="", eval=FALSE}
keeping the Categorical Variables&Keeping SMOTE(final model 4*128)
```

```{python active="", eval=FALSE}
[1.6464146375656128, 0.400329053401947]    4*32 no overfitting to the trainng data as Train_Accuracy and Val_Accuracy are both 48%, Train_Loss and Val_Loss are both 1.5. 
implementing bigger model to increase accuray, allow the model to fit training dataset better.
```

```{python active="", eval=FALSE}
[1.5717041492462158, 0.4352629482746124]   4*64 no overfitting to the trainng data as Train_Accuracy and Val_Accuracy are both 50.5%, Train_Loss and Val_Loss are both 1.43. 
```

```{python active="", eval=FALSE}
[1.6884784698486328, 0.4317558705806732]   3*128 no overfitting to the trainng data as Train_Accuracy and Val_Accuracy are both 51%, Train_Loss and Val_Loss are both 1.42
```

```{python active="", eval=FALSE}
[1.6598726511001587, 0.42012324929237366]  4*128 no overfitting to the trainng data as Train_Accuracy and Val_Accuracy are both 52.5%, Train_Loss and Val_Loss are both 1.37. 
```

```{python active="", eval=FALSE}
[2.062901020050049, 0.4144512712955475]    4*256 no overfitting to the trainng data as Train_Accuracy and Val_Accuracy are both 51%, Train_Loss and Val_Loss are both 1.44.
```

```{python active="", eval=FALSE}
[2.4160232543945312, 0.010211003012955189] 7*256 no overfitting to the trainng data as Train_Accuracy and Val_Accuracy are both 51%, Train_Loss and Val_Loss are both 1.40. Then the accuracy rapidly deteriorated to 0.09, then stop training.
```

```{python active="", eval=FALSE}
Reasons why potentially may not use SMOTE: 
Since we are only using SMOTE on the train&val dataset, this is causing a difference between train&val data and test data. In other words, SMOTED data may deviate from the original data. Thus, it causes a significant gap between train/val accuracy and test accuracy. Let the model learn from a deviated data may also cause the model has bad out-of-sample performance, such that the model may fit really well to train/val but the performance on test lags behind.
```

```{python active="", eval=FALSE}
Without SMOTE(final model 4*128)
```

```{python active="", eval=FALSE}
[1.2754151821136475, 0.5730934739112854]  3*128 no overfitting to the trainng data as Train_Accuracy and Val_Accuracy are both 57%, Train_Loss and Val_Loss are both 1.24
```

```{python active="", eval=FALSE}
[1.2754151821136475, 0.5730934739112854]  4*128 no overfitting to the trainng data as Train_Accuracy and Val_Accuracy are both 57%, Train_Loss and Val_Loss are both 1.24
```

```{python active="", eval=FALSE}
[1.2682744264602661, 0.5701348185539246]  4*256 no overfitting to the trainng data as Train_Accuracy and Val_Accuracy are both 57%, Train_Loss and Val_Loss are both 1.24. 
```

```{python active="", eval=FALSE}
[1.2567076683044434, 0.5648308396339417]  5*128 no overfitting to the trainng data as Train_Accuracy and Val_Accuracy are both 56%, Train_Loss and Val_Loss are both 1.25. 
```

```{python active="", eval=FALSE}
[1.2791824340820312, 0.5616196393966675]  8*256 no overfitting to the trainng data as Train_Accuracy and Val_Accuracy are both 55%, Train_Loss and Val_Loss are both 1.28.
```

```{python active="", eval=FALSE}
[1.2806458473205566, 0.5636618137359619]  10*512 no overfitting to the trainng data as Train_Accuracy and Val_Accuracy are both 56%, Train_Loss and Val_Loss are both randomly fluctuate between 1.28~1.33.
```

```{python active="", eval=FALSE}
I thought having a huge Model can fit the data as well as possible, because variance is not a concern so far,
and I hope to increase accuracy by introducing more parameters into the model, but even with more parameter the NN fails to fit the data better.
```

```{python active="", eval=FALSE}
Thus I go back and see whether a model smaller than 4*256 would be better
```

```{python active="", eval=FALSE}
Reference Andrew ng
```

```{python active="", eval=FALSE}
comparasion between SMOTE and NON-SMOTE based on the best NN architecture selected. To See whether SMOTE the data helps the model to identify the minority class better, introducing F1-Score
```
